#!/usr/bin/env python3
"""
Test script to generate a sample email with the new light-mode design.
"""

import yaml
from render import EmailRenderer
from datetime import datetime

# Mock data for testing
mock_papers = [
    {
        'arxiv_id': '2508.10333v1',
        'title': 'ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver',
        'abstract': 'Recent advances in Vision-Language-Action (VLA) models have enabled robotic agents to integrate multimodal understanding with action execution. This paper introduces ReconVLA, a model that improves visual grounding for manipulation by using a reconstructive objective.',
        'categories': ['cs.RO', 'cs.CV'],
        'version': 1,
        'keep': True,
        'relevance_score': 85,
        'buckets': ['VLA / LLM-in-the-Loop', 'Perception for Manipulation'],
        'why_it_matters': 'For our dual-arm mobile manipulator operating in complex human environments, accurately identifying and focusing on the correct object is critical. This paper offers a concrete method to improve the visual grounding of our VLA-based policies.',
        'summary': 'This paper introduces ReconVLA, a Vision-Language-Action model that improves visual grounding for manipulation by using a reconstructive objective. The core method involves a diffusion transformer that reconstructs the target gaze region of an image from the VLA visual outputs.',
        'code_urls': ['https://github.com/example/reconvla'],
        'dataset_urls': [],
        'arxiv_link': 'https://arxiv.org/abs/2508.10333',
        'pdf_link': 'https://arxiv.org/pdf/2508.10333.pdf',
        'in_top_picks': True
    },
    {
        'arxiv_id': '2508.10511v1',
        'title': 'KDPE: A Kernel Density Estimation Strategy for Diffusion Policy Trajectory Selection',
        'abstract': 'Learning robot policies that capture multimodality in the training data has been a long-standing open challenge for behavior cloning. This paper introduces KDPE, a method using Kernel Density Estimation to filter and select the best trajectories generated by a Diffusion Policy.',
        'categories': ['cs.RO'],
        'version': 1,
        'keep': True,
        'relevance_score': 70,
        'buckets': ['Imitation / Diffusion / RL', 'Safety & Reliability'],
        'why_it_matters': 'Diffusion policies are a key area of interest for us. This paper addresses a major weakness: their stochasticity and tendency to learn outliers, which can lead to unsafe or failed actions.',
        'summary': 'This paper introduces KDPE, a method using Kernel Density Estimation to filter and select the best trajectories generated by a Diffusion Policy. This improves the policy reliability by rejecting stochastic or out-of-distribution outputs.',
        'code_urls': ['https://github.com/example/kdpe'],
        'dataset_urls': [],
        'arxiv_link': 'https://arxiv.org/abs/2508.10511',
        'pdf_link': 'https://arxiv.org/pdf/2508.10511.pdf',
        'in_top_picks': True
    },
    {
        'arxiv_id': '2508.10399v1',
        'title': 'Large Model Empowered Embodied AI: A Survey on Decision-Making and Embodied Learning',
        'abstract': 'Embodied AI aims to develop intelligent systems with physical forms capable of perceiving, decision-making, acting, and learning in real-world environments. This survey provides a comprehensive overview of how large models are being used to advance embodied AI.',
        'categories': ['cs.RO'],
        'version': 1,
        'keep': True,
        'relevance_score': 70,
        'buckets': ['VLA / LLM-in-the-Loop', 'Imitation / Diffusion / RL'],
        'why_it_matters': 'As a comprehensive survey, this paper is a critical resource for understanding the current landscape of large models in robotics. It helps our team quickly get up to speed on state-of-the-art approaches.',
        'summary': 'This survey provides a comprehensive overview of how large models are being used to advance embodied AI, focusing on decision-making paradigms like Vision-Language-Action (VLA) models and learning methodologies such as imitation and reinforcement learning.',
        'code_urls': [],
        'dataset_urls': [],
        'arxiv_link': 'https://arxiv.org/abs/2508.10399',
        'pdf_link': 'https://arxiv.org/pdf/2508.10399.pdf',
        'in_top_picks': True
    }
]

# Load config
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)

# Create renderer
renderer = EmailRenderer(config)

# Organize papers
top_picks = mock_papers[:3]
buckets = {
    'VLA / LLM-in-the-Loop': [mock_papers[0], mock_papers[2]],
    'Imitation / Diffusion / RL': [mock_papers[1], mock_papers[2]],
    'Perception for Manipulation': [mock_papers[0]],
    'Safety & Reliability': [mock_papers[1]]
}
also_noteworthy = []
filtered_out = []

# Render email
html = renderer.render(
    top_picks=top_picks,
    buckets=buckets,
    also_noteworthy=also_noteworthy,
    filtered_out=filtered_out,
    metadata={'total_papers': len(mock_papers)}
)

# Save to file
with open('test_light_mode_output.html', 'w') as f:
    f.write(html)

print("âœ… Generated test email with light-mode design: test_light_mode_output.html")
print("ðŸ“§ You can open this file in your browser to see the beautiful new design!")
